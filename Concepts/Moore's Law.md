#Concepts 
# Moore's Law

> The number of transistors in an integrated circuit doubles approximately every two years.

Often used to illustrate the sheer speed at which semiconductor and chip technology has improved, Moore's prediction has proven to be highly accurate over from the 1970s to the late 2000s. In more recent years, the trend has changed slightly, partly due to physical limitations on the degree to which components can be miniaturised. However, advancements in parallelisation, and potentially revolutionary changes in semiconductor technology and quantum computing may mean that Moore's Law could continue to hold true for decades to come.


Related:
- [[Exponential Change]]


Source:
- https://en.wikipedia.org/wiki/Moore%27s_law

---


Any one of several similar folk theorems that fit computing capacity or cost to a 2t exponential curve, with doubling time close to a year. The most common fits component density to such a curve (previous versions of this entry gave that form). Another variant asserts that the dollar cost of constant computing power decreases on the same curve. The original Moore's Law, first uttered in 1965 by semiconductor engineer Gordon Moore (who co-founded Intel four years later), spoke of the number of components on the lowest-cost silicon integrated circuits â€” but Moore's own formulation varied somewhat over the years, and reconstructing the meaning of the terminology he used in the original turns out to be fraught with difficulties. Further variants were spawned by Intel's PR department and various journalists.

It has been [shown](http://firstmonday.org/issues/issue7_11/tuomi/index.html) that none of the variants of Moore's Law actually fit the data very well (the price curves within DRAM generations perhaps come closest). Nevertheless, Moore's Law is constantly invoked to set up expectations about the next generation of computing technology.

Jargon File